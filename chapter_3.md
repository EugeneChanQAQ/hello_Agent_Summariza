## Chapter 3
__学习心得__：  
### 发展历史：  
统计语言模型（链式法则）

--> 马尔可夫假设（N-gram）：通过最大似然估计计算  
缺陷：数据稀疏性、泛化能力差无法理解语义

--> 神经网络语言模型与词嵌入  
将词在高维向量空间中表示，语义相近的词在向量空间中也相近。利用神经网络的拟合。输入前n-1个词的向量，输出词汇表中每个词在当前上下文后出现的概率分布。  
一般通过***余弦相似度***计算两个词之间的相关性。  
缺陷：上下文窗口是固定的，只能考虑固定数量的前文。

-->循环神经网络（RNN）和长短时记忆网络（LSTM）  
RNN：为网络增加"记忆能力"（通过在处理序列的每一步引入隐藏状态）  
缺陷：长期依赖问题（因为需要在每一步通过反向传播来调整权重，如果序列很长，反向传播计算梯度时由于连乘很容易造成***梯度爆炸***或者***梯度消失***，难以捕捉长距离依赖关系。  
LSTM：改进版RNN

--> Transformer  
分为Encoder和Decoder两部分，Encoder理解输入的句子，Decoder生成目标句子。  
通过注意力机制引入的Q、K、V来进行学习权重，又引入多头注意力机制来对语言从多种角度进行理解。  
在每个注意力层之后引入FFN（前馈神经网络）：由两个先行变换和一个ReLU激活函数组成，用于提取更高阶的特征，帮助模型学习更丰富的特征表示。  
每个子模块又引入残差连接（解决网络中的梯度消失问题）和归一化（解决训练过程中的内部协变量偏移问题，使每一层的输入分布保持稳定，从而加速模型收敛并提高训练的稳定性）。  
位置编码：采用了绝对位置编码，后面学习补充RoPE。

--> Decode-Only(自回归)  
引入Masked Self-Attention

### 与LLM交互
#### 提示词
- 模型采样参数：Temperature、Top-k、Top-p
- 零样本、单样本与少样本提示
- 指令调优
- 基础提示技巧：角色扮演、上下文示例
- 思维链：在Prompt中加入简单的引导语，引导模型进行逐步思考。
#### 文本分词
早期分为两类（按词分词、按字符分词）

--> 字节对编码（Byte-Pair Encoding）

--> 通过对BPE改进衍生出（WordPiece、SentencePiece）

### Agent开发时模型选择
- 性能与能力（可参考LMSys Chatbot Arena Leaderboard）
- 成本（API调用费用，一般按token计费）
- 速度（Agent注重响应速度，可使用轻量级或经过优化的模型例如gpt-3.5 turbo等）
- 上下文窗口（model一次性处理的token数量上限）
- 部署方式
- 生态与工具链
- 可微调性与定制化
- 安全性与伦理

### LLM缩放法则与局限性
#### 缩放法则（ Scaling Laws)：模型性能、参数量、训练数据量以及计算资源之间存在可预测的幂律关系。
***模型参数量和训练数据量之间存在最优配比***：Chinchilla定律（训练token数是模型参数的20倍）







